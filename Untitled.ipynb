{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#====================================================================\n",
    "# for visualizing network\n",
    "from vis.utils import utils\n",
    "from vis.visualization import overlay\n",
    "from keras import activations\n",
    "import cv2\n",
    "\n",
    "from vis.utils import utils  \n",
    "from keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from vis.visualization import visualize_cam\n",
    "\n",
    "# for plot \n",
    "from vis.utils import utils\n",
    "from matplotlib import pyplot as plt\n",
    "from vis.visualization import visualize_cam\n",
    "\n",
    "import csv \n",
    "#===================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#load model and swap last layer for linear. \n",
    "model = load_model('model_window_k2_drives_1.h5')\n",
    "\n",
    "# from Udacity class material, reads in lines for image names\n",
    "lines = []\n",
    "with open('/home/andrewrs/Desktop/udacity/data/train3/driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "            \n",
    "#=================================================\n",
    "# rewrite as function!!! \n",
    "def image_mask(image):\n",
    "    # make zeros\n",
    "    mask = np.zeros(image.shape, dtype=np.uint8)\n",
    "    # define the corners\n",
    "    #cut top left and right corners, top and bottom\n",
    "    corners = np.array([[(0, 80),(0, 25), (110,0), (210, 0), (320,25), (320, 80)]], dtype=np.int32)\n",
    "    # get channel number\n",
    "    num_channels = image.shape[2] \n",
    "    # define no color\n",
    "    mask_color = (255,)*num_channels\n",
    "    # get mask\n",
    "    mask = cv2.fillPoly(mask, corners, mask_color)\n",
    "    # from Masterfool: use cv2.fillConvexPoly if you know it's convex\n",
    "    # Use the mask\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    # get correct color scheme !! for plotting and saving only \n",
    "    #out_image = cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR)\n",
    "    return masked_image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_cut = lines[2870:3500]\n",
    "\n",
    "# creates an image with attention overlay for each picture fed in. \n",
    "def attention_overlay(lines, out_loc='/home/andrewrs/Desktop/udacity/mod_data/', model = model):\n",
    "    for line in lines:\n",
    "        source_path = line[0]\n",
    "        # split character modified because image data was collected on windows 10\n",
    "        filename = source_path.split('\\\\')[-1]\n",
    "        current_path = '/home/andrewrs/Desktop/udacity/data/train3/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        crop_img = image[65:140,0:320,:]\n",
    "        masked_image = image_mask(crop_img)\n",
    "        grads = visualize_cam(model, layer_idx=-9, filter_indices=16, seed_input=masked_image, backprop_modifier='guided')        \n",
    "        #heatmap = np.uint8(cm.jet(grads))\n",
    "        out_image = overlay(grads, masked_image, alpha = 0.4)\n",
    "        out_image = cv2.cvtColor(out_image, cv2.COLOR_RGB2BGR)\n",
    "        file_path = out_loc + filename\n",
    "        cv2.imwrite(file_path, out_image)\n",
    "        del image\n",
    "        del crop_img\n",
    "        del out_image\n",
    "    return 0\n",
    "            \n",
    "# speed it up \n",
    "#import multiprocessing as mp\n",
    "\n",
    "#pool = mp.Pool(processes=8)\n",
    "#pool.map(attention_overlay, lines_cut)\n",
    "attention_overlay(lines_cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "           \n",
    "lines_cut = lines[2000:3000]\n",
    "\n",
    "short = lines[0:3]\n",
    "images = []\n",
    "measurements = []\n",
    "for line in short:\n",
    "        for i in range(3):\n",
    "            source_path = line[i]\n",
    "            # split character modified because image data was collected on windows 10\n",
    "            filename = source_path.split('\\\\')[-1]\n",
    "            current_path = '/home/andrewrs/Desktop/udacity/data/train3/IMG/' + filename\n",
    "            image = cv2.imread(current_path)\n",
    "            image_c = image[60:160,0:320,:]\n",
    "            images.append(image)\n",
    "            measurement = float(line[3])\n",
    "            measurements.append(measurement)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an image with attention overlay for each picture fed in. \n",
    "def attention_overlay(lines, out_loc='/home/andrewrs/Desktop/udacity/mod_data/', model = model):\n",
    "    source_path = line[0]\n",
    "    # split character modified because image data was collected on windows 10\n",
    "    filename = source_path.split('\\\\')[-1]\n",
    "    current_path = '/home/andrewrs/Desktop/udacity/data/train3/IMG/' + filename\n",
    "    image = cv2.imread(current_path)\n",
    "    crop_img = image[0:160, 0:320, 0:3]\n",
    "    grads = visualize_cam(model, layer_idx=-2, filter_indices=0, seed_input=image, backprop_modifier='relu')        \n",
    "    #heatmap = np.uint8(cm.jet(grads))\n",
    "    out_image = overlay(grads, crop_img)\n",
    "    out_image = cv2.cvtColor(out_image, cv2.COLOR_RGB2BGR)\n",
    "    file_path = out_loc + filename\n",
    "    #return file_path, result\n",
    "    cv2.imwrite(file_path, out_image)\n",
    "# speed it up \n",
    "import multiprocessing as mp\n",
    "\n",
    "#pool = mp.Pool(processes=8)\n",
    "#pool.map(attention_overlay, lines_cut)\n",
    "#attention_overlay(lines_cut)\n",
    "\n",
    "pool = mp.Pool(4)\n",
    "pool.map(attention_overlay, lines_cut)\n",
    "# make an io handler \n",
    "#cv2.imwrite(file_path, out_image)\n",
    "\n",
    "#def io_handler():\n",
    "#    pool = multiprocessing.Pool(4)\n",
    " #   for result in p.imap(attention_overaly, lines_cut):\n",
    " #       cv2.imwrite(file_path, out_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#io_handler()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "#load model and swap last layer for linear. \n",
    "model = load_model('model_crop_k2.h5')\n",
    "\n",
    "# from Udacity class material, reads in lines for image names\n",
    "lines = []\n",
    "with open('/home/andrewrs/Desktop/udacity/data/train3/driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "\n",
    "            \n",
    "lines_cut = lines[2000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "# plot picture\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "# load example image from difficult part of track \n",
    "img1 = utils.load_img('/home/andrewrs/Desktop/udacity/data/train3/IMG/center_2017_09_06_10_42_37_667.jpg', target_size=(160, 320))\n",
    "\n",
    "# plot image \n",
    "plt.imshow(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_loc = '/home/andrewrs/Desktop/udacity/mod_data/'\n",
    "file_path = out_loc + 'att_' \n",
    "t_images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "out_loc = '/home/andrewrs/Desktop/udacity/mod_data/'\n",
    "source_path = line[i]\n",
    "# split character modified because image data was collected on windows 10\n",
    "filename = source_path.split('\\\\')[-1]\n",
    "current_path = '/home/andrewrs/Desktop/udacity/data/train3/IMG/' + filename\n",
    "image = cv2.imread(current_path)\n",
    "#crop_img = image[0:160, 0:320, 0:3]\n",
    "grads = visualize_cam(model, layer_idx=-2, filter_indices=0, seed_input=image, backprop_modifier='relu')        \n",
    "\n",
    "img1 = utils.load_img('/home/andrewrs/Desktop/udacity/data/train3/IMG/center_2017_09_06_10_42_37_667.jpg', target_size=(160, 320))\n",
    "out_image = overlay(grads, crop_img)\n",
    "file_path = out_loc + filename\n",
    "#cv2.imwrite(file_path, out_image)\n",
    "#plt.imshow(out_image)()\n",
    "\n",
    "grads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "# plot picture\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "# load example image from difficult part of track \n",
    "img1 = utils.load_img('/home/andrewrs/Desktop/udacity/data/train3/IMG/center_2017_09_06_10_42_37_667.jpg', target_size=(160, 320))\n",
    "\n",
    "# plot image \n",
    "plt.imshow(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 is the imagenet index corresponding to `ouzel`\n",
    "filter_indices=1\n",
    "crop_img = img1[0:160, 0:320, 0:3]\n",
    "grads = visualize_cam(model, layer_idx=-1, filter_indices=0, seed_input=img1, backprop_modifier=\n",
    "                     None)        \n",
    "# Lets overlay the heatmap onto original image.    \n",
    "test = np.uint8(cm.jet(grads))\n",
    "#plt.imshow(overlay(jet_heatmap, crop_img))\n",
    "tc = test[...,-1]\n",
    "#jet_heatmap.shape\n",
    "#img_BGRA.shape\n",
    "#plt.imshow(overlay(tc, crop_img))\n",
    "#plt.imshow(jet_heatmap)\n",
    "\n",
    "#tc = test[...,-1]\n",
    "plot.imshow()\n",
    "#tc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "# import libraries \n",
    "# for data read in and CNN\n",
    "import csv \n",
    "import cv2\n",
    "import numpy  as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D \t\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam \n",
    "\n",
    "# for balancing the data by steering angle\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import random\n",
    "#====================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('/home/andrewrs/Desktop/udacity/data/train3/driving_log.csv') as csvfile:\n",
    "\treader = csv.reader(csvfile)\n",
    "\tfor line in reader:\n",
    "\t\tlines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================================================\n",
    "# plot picture\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "# load example image from difficult part of track \n",
    "img1 = utils.load_img('/home/andrewrs/Desktop/udacity/data/train3/IMG/center_2017_09_06_10_42_37_667.jpg', target_size=(160, 320))\n",
    "\n",
    "# plot image \n",
    "plt.imshow(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\t\n",
    "# from Udacity class material, reads in X\n",
    "images = []\n",
    "measurements = []\n",
    "i=0\n",
    "source_path = line[i]\n",
    "# split character modified because image data was collected on windows 10\n",
    "filename = source_path.split('\\\\')[-1]\n",
    "current_path = '/home/andrewrs/Desktop/udacity/data/train3/IMG/' + filename\n",
    "image = cv2.imread(current_path)\n",
    "# add cropping\n",
    "image_c = image[60:160,0:320,:]\n",
    "#image_corners\n",
    "\n",
    "# zero out corners\n",
    "\n",
    "# original image\n",
    "#source [https://stackoverflow.com/questions/15341538/numpy-opencv-2-how-do-i-crop-non-rectangular-region]\n",
    "# -1 loads as-is so if it will be 3 or 4 channel as the original\n",
    "#image = cv2.imread('image.png', -1)\n",
    "# mask defaulting to black for 3-channel and transparent for 4-channel\n",
    "# (of course replace corners with yours)\n",
    "\n",
    "# make zeros\n",
    "mask = np.zeros(image_c.shape, dtype=np.uint8)\n",
    "\n",
    "# define the corners\n",
    "#cut top left and right corners, top and bottom\n",
    "corners = np.array([[(0, 80),(0, 25), (110,5), (210, 5), (320,25), (320, 80)]], dtype=np.int32)\n",
    "\n",
    "# get channel number\n",
    "num_channels = image.shape[2] \n",
    "\n",
    "# define no color\n",
    "mask_color = (255,)*num_channels\n",
    "\n",
    "# get mask\n",
    "mask = cv2.fillPoly(mask, corners, mask_color)\n",
    "# from Masterfool: use cv2.fillConvexPoly if you know it's convex\n",
    "\n",
    "# Use the mask\n",
    "masked_image = cv2.bitwise_and(image_c, mask)\n",
    "\n",
    "# get correct color scheme\n",
    "out_image = cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#  plot check\n",
    "plt.imshow(out_image)\n",
    "\n",
    "#=================================================\n",
    "# rewrite as function!!! \n",
    "def image_mask(image):\n",
    "    # make zeros\n",
    "    mask = np.zeros(image_c.shape, dtype=np.uint8)\n",
    "    # define the corners\n",
    "    #cut top left and right corners, top and bottom\n",
    "    corners = np.array([[(0, 80),(0, 25), (110,5), (210, 5), (320,25), (320, 80)]], dtype=np.int32)\n",
    "    # get channel number\n",
    "    num_channels = image.shape[2] \n",
    "    # define no color\n",
    "    mask_color = (255,)*num_channels\n",
    "    # get mask\n",
    "    mask = cv2.fillPoly(mask, corners, mask_color)\n",
    "    # from Masterfool: use cv2.fillConvexPoly if you know it's convex\n",
    "    # Use the mask\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    # get correct color scheme !! for plotting and saving only \n",
    "    #out_image = cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR)\n",
    "    return masked_image\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#plt.imshow(image_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
